# Sports Events Tracker

A Spring Boot microservice that tracks live sports events by accepting status updates, for each event live calls an external APIs, transforms the response into a
message and publishing to Kafka.

## ğŸš€ Features

- `POST /events/status` endpoint that accepts a JSON payload.
- Scheduled polling every 10 seconds to fetch updates for live events.
- Publishes live event data to Kafka with retry logic and logging.
- Kafka retry handling with `RetryTemplate`.
- Unit and integration tests included.

---

## ğŸ› ï¸ Technologies

- Java 17+
- Spring Boot
- Spring Kafka
- Maven
- JUnit 5
- Mockito
- Embedded Kafka (for integration testing)

---

## ğŸ“¦ Setup & Run

### 1. Clone the repository

```bash
git clone https://github.com/taniabadescu27/sports-events.git
cd sports-events
```

### 2. Start Kafka (locally or via Docker)

If using Docker:

```bash
docker-compose up -d
```

### 3. Run the application

```bash
mvn spring-boot:run
```
The service will start at:

```
http://localhost:8080
```

## ğŸ“® API Usage

### POST /events/status

Updates the statuses of one or more events.

#### ğŸ”§ Request Example

**Method**: `POST`  
**URL**: `http://localhost:8080/events/status`  
**Headers**:
- `Content-Type: application/json`

**Body (raw JSON)**:
```json
[
  {
    "eventId": "56444",
    "status": "LIVE"
  },
  {
    "eventId": "98711",
    "status": "NOT_LIVE"
  }
]
```
### âœ… Tested using Postman:
The above request was successfully tested using Postman by sending it to the endpoint while the application was running locally. A 200 OK response confirms the update was processed correctly.


## âœ… Running Tests

### Run all tests:

```bash
mvn test
```
This will run all unit and integration tests in the junit.tests package.


## ğŸ§  Design Decisions

- **Used a `ConcurrentHashMap`** to store event status safely across threads, ensuring thread-safety in concurrent operations.
  
- **Polling of live events** is scheduled every 10 seconds using `@Scheduled` to ensure the system periodically fetches updates.

- **Kafka publishing** is wrapped in a `RetryTemplate` to handle transient failures and ensure reliable delivery of messages.

- **Logging**: All failures are logged properly, and the system is designed to be resilient, retrying failed operations and providing detailed logging for debugging and monitoring.

- **@Valid** and custom validation used to enforce eventId and status input correctness.


## ğŸ¤– AI-Assisted Parts

- Some classes and methods (e.g., `EventPublishingService`, test templates) were initially generated using ChatGPT.

- All AI-generated code was:
  - Reviewed for correctness and compliance with project structure.
  - Modified to ensure testability and integration with existing components.
  - Verified using unit/integration tests.

- Documentation (this README) was also assisted with AI suggestions and edited manually.

### ğŸ“ Folder Structure

```
src/
 â””â”€â”€ main/
     â””â”€â”€ java/com/example/tracker/
         â”œâ”€â”€ client/
         â”œâ”€â”€ config/
         â”œâ”€â”€ controller/
         â”œâ”€â”€ exceptions/
         â”œâ”€â”€ model/
         â””â”€â”€ service/

 â””â”€â”€ test/
     â””â”€â”€ java/com/example/tracker/
```

